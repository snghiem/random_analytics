{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import Imputer\n",
    "from IPython.display import Image  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "import numpy as np\n",
    "import pydotplus\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "random.seed(123435454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/Applications/Python-3.5.2/Build/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (38,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('edu_chile_survey_output.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.concat([dat.loc[:,'q1':'q6_lang_orig'],dat.loc[:,'female':'rbdRating']], axis=1)\n",
    "y = dat['search1_clicked_button'].replace(np.nan, 0).replace('yes',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q4_cost_1_orig</th>\n",
       "      <th>q4_cost_2_orig</th>\n",
       "      <th>q4_cost_3_orig</th>\n",
       "      <th>q5_mi_ing_1_orig</th>\n",
       "      <th>q5_mi_ing_2_orig</th>\n",
       "      <th>q5_mi_ing_3_orig</th>\n",
       "      <th>q5_tip_ing_1_orig</th>\n",
       "      <th>q5_tip_ing_2_orig</th>\n",
       "      <th>q5_tip_ing_3_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.963900e+04</td>\n",
       "      <td>1.525600e+04</td>\n",
       "      <td>1.284400e+04</td>\n",
       "      <td>1.850700e+04</td>\n",
       "      <td>1.542000e+04</td>\n",
       "      <td>1.361900e+04</td>\n",
       "      <td>1.519700e+04</td>\n",
       "      <td>1.260500e+04</td>\n",
       "      <td>1.119500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.657677e+14</td>\n",
       "      <td>3.564151e+06</td>\n",
       "      <td>3.114295e+85</td>\n",
       "      <td>1.071742e+06</td>\n",
       "      <td>9.881778e+05</td>\n",
       "      <td>1.005502e+06</td>\n",
       "      <td>2.351188e+06</td>\n",
       "      <td>1.072769e+06</td>\n",
       "      <td>9.987316e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.928624e+16</td>\n",
       "      <td>6.190200e+07</td>\n",
       "      <td>3.529473e+87</td>\n",
       "      <td>1.464748e+07</td>\n",
       "      <td>1.084358e+07</td>\n",
       "      <td>1.193283e+07</td>\n",
       "      <td>1.624345e+08</td>\n",
       "      <td>1.125497e+07</td>\n",
       "      <td>9.488580e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>3.900000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>3.800000e+05</td>\n",
       "      <td>4.400000e+05</td>\n",
       "      <td>4.300000e+05</td>\n",
       "      <td>4.200000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.440000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>6.700000e+05</td>\n",
       "      <td>6.600000e+05</td>\n",
       "      <td>6.200000e+05</td>\n",
       "      <td>7.200000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>3.520000e+06</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>9.900000e+05</td>\n",
       "      <td>1.100000e+06</td>\n",
       "      <td>1.050000e+06</td>\n",
       "      <td>1.010000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.111111e+19</td>\n",
       "      <td>5.000000e+09</td>\n",
       "      <td>4.000000e+89</td>\n",
       "      <td>1.400000e+09</td>\n",
       "      <td>1.200000e+09</td>\n",
       "      <td>1.200000e+09</td>\n",
       "      <td>2.000000e+10</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q4_cost_1_orig  q4_cost_2_orig  q4_cost_3_orig  q5_mi_ing_1_orig  \\\n",
       "count    1.963900e+04    1.525600e+04    1.284400e+04      1.850700e+04   \n",
       "mean     5.657677e+14    3.564151e+06    3.114295e+85      1.071742e+06   \n",
       "std      7.928624e+16    6.190200e+07    3.529473e+87      1.464748e+07   \n",
       "min      1.000000e+00    1.000000e+00    1.000000e+00      1.000000e+00   \n",
       "25%      1.200000e+06    1.330000e+06    1.330000e+06      3.900000e+05   \n",
       "50%      2.440000e+06    2.500000e+06    2.500000e+06      6.700000e+05   \n",
       "75%      3.500000e+06    3.520000e+06    3.500000e+06      1.000000e+06   \n",
       "max      1.111111e+19    5.000000e+09    4.000000e+89      1.400000e+09   \n",
       "\n",
       "       q5_mi_ing_2_orig  q5_mi_ing_3_orig  q5_tip_ing_1_orig  \\\n",
       "count      1.542000e+04      1.361900e+04       1.519700e+04   \n",
       "mean       9.881778e+05      1.005502e+06       2.351188e+06   \n",
       "std        1.084358e+07      1.193283e+07       1.624345e+08   \n",
       "min        1.000000e+00      1.000000e+00       1.000000e+00   \n",
       "25%        4.000000e+05      3.800000e+05       4.400000e+05   \n",
       "50%        6.600000e+05      6.200000e+05       7.200000e+05   \n",
       "75%        1.000000e+06      9.900000e+05       1.100000e+06   \n",
       "max        1.200000e+09      1.200000e+09       2.000000e+10   \n",
       "\n",
       "       q5_tip_ing_2_orig  q5_tip_ing_3_orig  \n",
       "count       1.260500e+04       1.119500e+04  \n",
       "mean        1.072769e+06       9.987316e+05  \n",
       "std         1.125497e+07       9.488580e+06  \n",
       "min         1.000000e+00       1.000000e+00  \n",
       "25%         4.300000e+05       4.200000e+05  \n",
       "50%         7.000000e+05       7.000000e+05  \n",
       "75%         1.050000e+06       1.010000e+06  \n",
       "max         1.000000e+09       1.000000e+09  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all non-numeric characters in the self-estimation variables\n",
    "estimated_values= ['q4_cost_1_orig','q4_cost_2_orig','q4_cost_3_orig',\n",
    "                  'q5_mi_ing_1_orig', 'q5_mi_ing_2_orig','q5_mi_ing_3_orig',\n",
    "                  'q5_tip_ing_1_orig','q5_tip_ing_2_orig','q5_tip_ing_3_orig']\n",
    "\n",
    "for i in estimated_values:\n",
    "    x[i] = x[i].str.extract('(?P<digit>([0-9]+))',expand=False)\n",
    "    x[i] = x[i].astype(float)  \n",
    "    x[i] = x[i].replace(0, np.nan)\n",
    "    \n",
    "x[estimated_values].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q4_cost_1_orig</th>\n",
       "      <th>q4_cost_2_orig</th>\n",
       "      <th>q4_cost_3_orig</th>\n",
       "      <th>q5_mi_ing_1_orig</th>\n",
       "      <th>q5_mi_ing_2_orig</th>\n",
       "      <th>q5_mi_ing_3_orig</th>\n",
       "      <th>q5_tip_ing_1_orig</th>\n",
       "      <th>q5_tip_ing_2_orig</th>\n",
       "      <th>q5_tip_ing_3_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.963100e+04</td>\n",
       "      <td>1.525300e+04</td>\n",
       "      <td>1.284000e+04</td>\n",
       "      <td>1.850600e+04</td>\n",
       "      <td>1.541900e+04</td>\n",
       "      <td>1.361800e+04</td>\n",
       "      <td>1.519600e+04</td>\n",
       "      <td>1.260500e+04</td>\n",
       "      <td>1.119500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.611960e+06</td>\n",
       "      <td>2.712561e+06</td>\n",
       "      <td>2.640066e+06</td>\n",
       "      <td>9.961487e+05</td>\n",
       "      <td>9.104158e+05</td>\n",
       "      <td>9.174569e+05</td>\n",
       "      <td>1.035206e+06</td>\n",
       "      <td>1.072769e+06</td>\n",
       "      <td>9.987316e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.156370e+06</td>\n",
       "      <td>1.003713e+07</td>\n",
       "      <td>5.606391e+06</td>\n",
       "      <td>1.043070e+07</td>\n",
       "      <td>4.933676e+06</td>\n",
       "      <td>6.068116e+06</td>\n",
       "      <td>8.168338e+06</td>\n",
       "      <td>1.125497e+07</td>\n",
       "      <td>9.488580e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>3.900000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>3.800000e+05</td>\n",
       "      <td>4.400000e+05</td>\n",
       "      <td>4.300000e+05</td>\n",
       "      <td>4.200000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.440000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>6.700000e+05</td>\n",
       "      <td>6.600000e+05</td>\n",
       "      <td>6.200000e+05</td>\n",
       "      <td>7.200000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>3.520000e+06</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>9.900000e+05</td>\n",
       "      <td>1.100000e+06</td>\n",
       "      <td>1.050000e+06</td>\n",
       "      <td>1.010000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+08</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>4.600000e+08</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q4_cost_1_orig  q4_cost_2_orig  q4_cost_3_orig  q5_mi_ing_1_orig  \\\n",
       "count    1.963100e+04    1.525300e+04    1.284000e+04      1.850600e+04   \n",
       "mean     2.611960e+06    2.712561e+06    2.640066e+06      9.961487e+05   \n",
       "std      5.156370e+06    1.003713e+07    5.606391e+06      1.043070e+07   \n",
       "min      1.000000e+00    1.000000e+00    1.000000e+00      1.000000e+00   \n",
       "25%      1.200000e+06    1.330000e+06    1.330000e+06      3.900000e+05   \n",
       "50%      2.440000e+06    2.500000e+06    2.500000e+06      6.700000e+05   \n",
       "75%      3.500000e+06    3.520000e+06    3.500000e+06      1.000000e+06   \n",
       "max      5.000000e+08    1.000000e+09    4.600000e+08      1.000000e+09   \n",
       "\n",
       "       q5_mi_ing_2_orig  q5_mi_ing_3_orig  q5_tip_ing_1_orig  \\\n",
       "count      1.541900e+04      1.361800e+04       1.519600e+04   \n",
       "mean       9.104158e+05      9.174569e+05       1.035206e+06   \n",
       "std        4.933676e+06      6.068116e+06       8.168338e+06   \n",
       "min        1.000000e+00      1.000000e+00       1.000000e+00   \n",
       "25%        4.000000e+05      3.800000e+05       4.400000e+05   \n",
       "50%        6.600000e+05      6.200000e+05       7.200000e+05   \n",
       "75%        1.000000e+06      9.900000e+05       1.100000e+06   \n",
       "max        6.000000e+08      6.000000e+08       1.000000e+09   \n",
       "\n",
       "       q5_tip_ing_2_orig  q5_tip_ing_3_orig  \n",
       "count       1.260500e+04       1.119500e+04  \n",
       "mean        1.072769e+06       9.987316e+05  \n",
       "std         1.125497e+07       9.488580e+06  \n",
       "min         1.000000e+00       1.000000e+00  \n",
       "25%         4.300000e+05       4.200000e+05  \n",
       "50%         7.000000e+05       7.000000e+05  \n",
       "75%         1.050000e+06       1.010000e+06  \n",
       "max         1.000000e+09       1.000000e+09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems like 10^9 might be the maximum values for each of these variables.\n",
    "# Anything higher than that I consider as outliers. For simplicity, I assign\n",
    "# the values of these outliers to NaN.\n",
    "\n",
    "for i in estimated_values:\n",
    "    x.loc[x[i]>np.power(10,9),i]=np.nan\n",
    "    \n",
    "x[estimated_values].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most of our dataset variables are categorical, the estimated values above \n",
    "# and the last two of math and language scores are numerical. I put them together here.\n",
    "numerical_variables = estimated_values + ['q6_math_orig','q6_lang_orig', 'PSU_leng_2013', 'PSU_mate_2013', 'PSU_2013','SIMCEMath10', 'SIMCELang10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporarily impute the missing values for basic predictive analytics\n",
    "imp = Imputer(missing_values='NaN', strategy='mean',axis=0)\n",
    "x[numerical_variables] = imp.fit_transform(x[numerical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  non-click       0.75      0.75      0.75      5233\n",
      "      click       0.44      0.45      0.44      2368\n",
      "\n",
      "avg / total       0.65      0.65      0.65      7601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use decision tree for only numerical variables\n",
    "def mytree(input_data):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(input_data, y, test_size = 0.2, random_state=0)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    y_pred = clf.predict(xtest)\n",
    "    target_names = ['non-click','click']\n",
    "    print(classification_report(ytest, y_pred, target_names = target_names))\n",
    "\n",
    "mytree(x[numerical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I tried to graph the tree but it's not clear/nice to look at.\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None,  filled=True, rounded=True,                          special_characters=True)  \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "# graph.write_pdf(\"educ.pdf\") \n",
    "# the graph is too large for the visual intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  non-click       0.70      0.96      0.81      5233\n",
      "      click       0.46      0.07      0.13      2368\n",
      "\n",
      "avg / total       0.62      0.68      0.60      7601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use Naive-Bayes for only self-estimated numerical variables\n",
    "def myNB(input_data):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(input_data, y, test_size = 0.2, random_state=0)\n",
    "    clf2 = GaussianNB()\n",
    "    y_pred2 = clf2.fit(xtrain, ytrain).predict(xtest)\n",
    "    target_names = ['non-click','click']\n",
    "    print(classification_report(ytest, y_pred2, target_names = target_names))\n",
    "\n",
    "myNB(x[numerical_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score for the decision tree is so highter for click (search) the self-estimated numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \t q1\n",
      "4 \t q2_tipo_1_orig\n",
      "3 \t q2_nivel_1\n",
      "142 \t q2_inst_1\n",
      "185 \t q2_carerra_1\n",
      "4 \t q2_tipo_2_orig\n",
      "3 \t q2_nivel_2\n",
      "146 \t q2_inst_2\n",
      "184 \t q2_carerra_2\n",
      "4 \t q2_tipo_3_orig\n",
      "3 \t q2_nivel_3\n",
      "155 \t q2_inst_3\n",
      "185 \t q2_carerra_3\n",
      "6 \t q3\n",
      "2 \t q4_nose_1_orig\n",
      "2 \t q4_nose_2_orig\n",
      "2 \t q4_nose_3_orig\n",
      "2 \t q5_mi_nose_1_orig\n",
      "2 \t q5_tip_nose_1_orig\n",
      "2 \t q5_mi_nose_2_orig\n",
      "2 \t q5_tip_nose_2_orig\n",
      "2 \t q5_mi_nose_3_orig\n",
      "2 \t q5_tip_nose_3_orig\n",
      "3 \t female\n",
      "6 \t mom_educ_simce\n",
      "6 \t dad_educ_simce\n",
      "4 \t schl_type\n",
      "6 \t rbdRating\n"
     ]
    }
   ],
   "source": [
    "# check on the number of unique values for each categorical feature\n",
    "for i in x.columns.values:\n",
    "    if i not in numerical_variables:\n",
    "        print(x[i].unique().size,\"\\t\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use the tree decision algorithm for this task. Notice that some variables like institution-vhoice and major choice include lots of values. At this time, I will not dig into creating (n-1) binary variables for all of these choices, I will ignore them for now and only consider those with the number of categorical values less than 32 (which is currently the offered capacity of sklearn as far as I remember)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now for this new analysis I will include both categorical features (less than 32 values),\n",
    "# and numerical features\n",
    "\n",
    "new_x = x\n",
    "for i in x.columns.values:\n",
    "    if (i not in numerical_variables): \n",
    "        if (x[i].unique().size<=32):\n",
    "            # I create binary variables for each categorical feature \n",
    "            # (d-1 binary variables for each d-value variable), merge them with the data set\n",
    "            new_x= pd.concat([new_x,pd.get_dummies(new_x[i])],axis=1)\n",
    "            \n",
    "            # and drop the first variable\n",
    "            new_x=new_x.drop(i, axis=1)\n",
    "        else:\n",
    "            # since they are institution-choice variables\n",
    "            new_x = new_x.drop(i, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  non-click       0.75      0.74      0.75      5233\n",
      "      click       0.45      0.46      0.46      2368\n",
      "\n",
      "avg / total       0.66      0.65      0.66      7601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mytree(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much improvement in F1-score for including all categorical variables in our analysis (after we tranformed all of these categorical variables into a list of binary variables). There is no guarantee that female/school-type/mother-education/etc make no impact on the prediction. Yet for now, I don't get that better improvement as including all variables. For me, the more simple, the better. Now I want to do some simple linear regression to test the statistical significance of each variable on the prediction of the deed of database search for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q4_cost_1_orig</th>\n",
       "      <td>-9.461723e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4_cost_2_orig</th>\n",
       "      <td>-1.866362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4_cost_3_orig</th>\n",
       "      <td>-5.240931e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_mi_ing_1_orig</th>\n",
       "      <td>-6.925668e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_mi_ing_2_orig</th>\n",
       "      <td>-4.150525e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_mi_ing_3_orig</th>\n",
       "      <td>1.211839e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_tip_ing_1_orig</th>\n",
       "      <td>1.279936e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_tip_ing_2_orig</th>\n",
       "      <td>-7.821905e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5_tip_ing_3_orig</th>\n",
       "      <td>-1.152505e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q6_math_orig</th>\n",
       "      <td>-1.153664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q6_lang_orig</th>\n",
       "      <td>2.472995e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSU_leng_2013</th>\n",
       "      <td>-6.113117e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSU_mate_2013</th>\n",
       "      <td>-7.213193e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSU_2013</th>\n",
       "      <td>1.726653e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIMCEMath10</th>\n",
       "      <td>6.213694e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIMCELang10</th>\n",
       "      <td>1.012516e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "q4_cost_1_orig    -9.461723e-10\n",
       "q4_cost_2_orig    -1.866362e-10\n",
       "q4_cost_3_orig    -5.240931e-11\n",
       "q5_mi_ing_1_orig  -6.925668e-12\n",
       "q5_mi_ing_2_orig  -4.150525e-10\n",
       "q5_mi_ing_3_orig   1.211839e-09\n",
       "q5_tip_ing_1_orig  1.279936e-08\n",
       "q5_tip_ing_2_orig -7.821905e-10\n",
       "q5_tip_ing_3_orig -1.152505e-08\n",
       "q6_math_orig      -1.153664e-04\n",
       "q6_lang_orig       2.472995e-04\n",
       "PSU_leng_2013     -6.113117e-04\n",
       "PSU_mate_2013     -7.213193e-04\n",
       "PSU_2013           1.726653e-03\n",
       "SIMCEMath10        6.213694e-03\n",
       "SIMCELang10        1.012516e-02"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LD = LinearRegression()\n",
    "LD.fit(x[numerical_variables],y)\n",
    "pd.DataFrame(LD.coef_,numerical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     search1_clicked_button   R-squared:                       0.013\n",
      "Model:                                OLS   Adj. R-squared:                  0.012\n",
      "Method:                     Least Squares   F-statistic:                     30.86\n",
      "Date:                    Tue, 13 Jun 2017   Prob (F-statistic):           3.18e-94\n",
      "Time:                            17:01:23   Log-Likelihood:                -24383.\n",
      "No. Observations:                   38004   AIC:                         4.880e+04\n",
      "Df Residuals:                       37987   BIC:                         4.894e+04\n",
      "Df Model:                              16                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.0153      0.021      0.721      0.471      -0.026       0.057\n",
      "q4_cost_1_orig    -9.462e-10   6.42e-10     -1.474      0.140    -2.2e-09    3.12e-10\n",
      "q4_cost_2_orig    -1.866e-10   4.02e-10     -0.465      0.642   -9.74e-10    6.01e-10\n",
      "q4_cost_3_orig    -5.241e-11   7.87e-10     -0.067      0.947   -1.59e-09    1.49e-09\n",
      "q5_mi_ing_1_orig  -6.926e-12   3.24e-10     -0.021      0.983   -6.42e-10    6.29e-10\n",
      "q5_mi_ing_2_orig  -4.151e-10   1.48e-09     -0.280      0.780   -3.32e-09    2.49e-09\n",
      "q5_mi_ing_3_orig   1.212e-09   1.29e-09      0.940      0.347   -1.31e-09    3.74e-09\n",
      "q5_tip_ing_1_orig   1.28e-08   4.79e-09      2.673      0.008    3.41e-09    2.22e-08\n",
      "q5_tip_ing_2_orig -7.822e-10   6.06e-10     -1.290      0.197   -1.97e-09    4.06e-10\n",
      "q5_tip_ing_3_orig -1.153e-08   4.78e-09     -2.413      0.016   -2.09e-08   -2.16e-09\n",
      "q6_math_orig         -0.0001   4.55e-05     -2.534      0.011      -0.000   -2.61e-05\n",
      "q6_lang_orig          0.0002   4.89e-05      5.059      0.000       0.000       0.000\n",
      "PSU_leng_2013        -0.0006      0.000     -1.916      0.055      -0.001     1.4e-05\n",
      "PSU_mate_2013        -0.0007      0.000     -2.308      0.021      -0.001      -0.000\n",
      "PSU_2013              0.0017      0.001      2.761      0.006       0.001       0.003\n",
      "SIMCEMath10           0.0062      0.005      1.321      0.186      -0.003       0.015\n",
      "SIMCELang10           0.0101      0.005      2.197      0.028       0.001       0.019\n",
      "==============================================================================\n",
      "Omnibus:                   123498.510   Durbin-Watson:                   2.009\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6752.692\n",
      "Skew:                           0.805   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.707   Cond. No.                     8.65e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.65e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x_OLS = sm.add_constant(x[numerical_variables])\n",
    "results= sm.OLS(y,x_OLS).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without testing any statistical significance, it's very clear to see very small (coefficient) potential impacts of these variables on the prediction so far. Further testing (F-test, etc) for model selection and specification should be implemented. Then OLS for statistical signicance could be introduced to see the potential significance of these variables. \n",
    "\n",
    "A simple OLS regression result above shows that most of variables of numerical values are statistical significant, except for _q6_lang_orig_.  Yet it seems like those with perceptions of self-estimated high tuitions and salaries from an institution or major choice will not likely to search in the database system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     search1_clicked_button   R-squared:                       0.172\n",
      "Model:                                OLS   Adj. R-squared:                  0.171\n",
      "Method:                     Least Squares   F-statistic:                     111.3\n",
      "Date:                    Tue, 13 Jun 2017   Prob (F-statistic):               0.00\n",
      "Time:                            17:01:24   Log-Likelihood:                -21033.\n",
      "No. Observations:                   38004   AIC:                         4.221e+04\n",
      "Df Residuals:                       37932   BIC:                         4.283e+04\n",
      "Df Model:                              71                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "===================================================================================================================================================================================================================================\n",
      "                                                                                                                                                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                                                                                                              -0.0313      0.077     -0.406      0.685      -0.182       0.120\n",
      "q4_cost_1_orig                                                                                                                                                  -9.823e-10   5.89e-10     -1.667      0.096   -2.14e-09    1.73e-10\n",
      "q4_cost_2_orig                                                                                                                                                  -1.058e-10   3.69e-10     -0.287      0.774   -8.28e-10    6.17e-10\n",
      "q4_cost_3_orig                                                                                                                                                   2.507e-10   7.22e-10      0.347      0.729   -1.17e-09    1.67e-09\n",
      "q5_mi_ing_1_orig                                                                                                                                                 2.504e-11   2.97e-10      0.084      0.933   -5.58e-10    6.08e-10\n",
      "q5_tip_ing_1_orig                                                                                                                                                8.756e-09   4.42e-09      1.982      0.048    9.55e-11    1.74e-08\n",
      "q5_mi_ing_2_orig                                                                                                                                                -3.425e-10   1.36e-09     -0.251      0.802   -3.01e-09    2.33e-09\n",
      "q5_tip_ing_2_orig                                                                                                                                               -6.474e-10   5.56e-10     -1.164      0.244   -1.74e-09    4.42e-10\n",
      "q5_mi_ing_3_orig                                                                                                                                                 1.172e-09   1.18e-09      0.989      0.323   -1.15e-09    3.49e-09\n",
      "q5_tip_ing_3_orig                                                                                                                                               -7.651e-09   4.41e-09     -1.736      0.083   -1.63e-08    9.86e-10\n",
      "q6_math_orig                                                                                                                                                    -3.511e-05   4.22e-05     -0.831      0.406      -0.000    4.77e-05\n",
      "q6_lang_orig                                                                                                                                                        0.0002   4.58e-05      4.077      0.000    9.69e-05       0.000\n",
      "PSU_leng_2013                                                                                                                                                      -0.0006      0.000     -1.948      0.051      -0.001    3.57e-06\n",
      "PSU_mate_2013                                                                                                                                                      -0.0005      0.000     -1.836      0.066      -0.001    3.54e-05\n",
      "PSU_2013                                                                                                                                                            0.0012      0.001      2.044      0.041    4.81e-05       0.002\n",
      "SIMCEMath10                                                                                                                                                         0.0045      0.004      1.034      0.301      -0.004       0.013\n",
      "SIMCELang10                                                                                                                                                         0.0047      0.004      1.097      0.273      -0.004       0.013\n",
      "Empece mis estudios de educacion superior, pero tuve que dejarlos un tiempo y los retomare nuevamente.                                                             -0.0066      0.013     -0.515      0.607      -0.032       0.018\n",
      "Estoy estudiando actualmente en una institucion de educacion superior y continuare en la misma carrera y en la misma institucion el ano que viene.                 -0.1016      0.030     -3.383      0.001      -0.160      -0.043\n",
      "Estoy estudiando actualmente en una institucion de educacion superior, pero pienso cambiarme a otra carrera en la misma institucion el ano que viene.              -0.0518      0.026     -2.015      0.044      -0.102      -0.001\n",
      "Estoy estudiando actualmente en una institucion de educacion superior, pero pienso cambiarme a otra institucion el ano que viene, cambiando tambien de carrera.    -0.0251      0.018     -1.363      0.173      -0.061       0.011\n",
      "Estoy estudiando actualmente en una institucion de educacion superior, pero pienso cambiarme a otra institucion el ano que viene, continuando la misma carrera      0.0122      0.031      0.389      0.698      -0.049       0.074\n",
      "Postulare a una institucion de educacion superior por primera vez.                                                                                                 -0.0011      0.009     -0.121      0.903      -0.019       0.016\n",
      "CFT                                                                                                                                                                -0.0145      0.261     -0.056      0.956      -0.527       0.498\n",
      "IP                                                                                                                                                                  0.0008      0.261      0.003      0.998      -0.511       0.512\n",
      "Universidad                                                                                                                                                         0.0867      0.261      0.332      0.740      -0.425       0.598\n",
      "Carreras Profesionales                                                                                                                                             -0.1262      0.259     -0.487      0.626      -0.634       0.382\n",
      "Carreras Tecnicas                                                                                                                                                  -0.1427      0.259     -0.550      0.582      -0.651       0.366\n",
      "CFT                                                                                                                                                                -0.1558      0.233     -0.667      0.505      -0.613       0.302\n",
      "IP                                                                                                                                                                 -0.1974      0.233     -0.846      0.398      -0.655       0.260\n",
      "Universidad                                                                                                                                                        -0.1828      0.233     -0.784      0.433      -0.640       0.274\n",
      "Carreras Profesionales                                                                                                                                              0.2423      0.233      1.040      0.298      -0.214       0.699\n",
      "Carreras Tecnicas                                                                                                                                                   0.1926      0.233      0.827      0.408      -0.264       0.649\n",
      "CFT                                                                                                                                                                -0.2433      0.198     -1.227      0.220      -0.632       0.145\n",
      "IP                                                                                                                                                                 -0.2319      0.198     -1.172      0.241      -0.620       0.156\n",
      "Universidad                                                                                                                                                        -0.2378      0.198     -1.203      0.229      -0.625       0.150\n",
      "Carreras Profesionales                                                                                                                                              0.3132      0.198      1.584      0.113      -0.074       0.701\n",
      "Carreras Tecnicas                                                                                                                                                   0.3059      0.198      1.545      0.122      -0.082       0.694\n",
      "Estoy absolutamente seguro(a).                                                                                                                                      0.3756      0.029     13.084      0.000       0.319       0.432\n",
      "Estoy bastante seguro(a).                                                                                                                                           0.3957      0.029     13.757      0.000       0.339       0.452\n",
      "Estoy medianamente seguro(a).                                                                                                                                       0.4098      0.029     14.144      0.000       0.353       0.467\n",
      "Estoy un poco seguro(a).                                                                                                                                            0.3880      0.030     12.887      0.000       0.329       0.447\n",
      "No estoy para nada seguro(a).                                                                                                                                       0.3926      0.032     12.106      0.000       0.329       0.456\n",
      "off                                                                                                                                                                -0.0010      0.039     -0.026      0.979      -0.077       0.075\n",
      "on                                                                                                                                                                 -0.0302      0.039     -0.782      0.434      -0.106       0.046\n",
      "off                                                                                                                                                                -0.0049      0.039     -0.126      0.900      -0.081       0.071\n",
      "on                                                                                                                                                                 -0.0264      0.039     -0.682      0.495      -0.102       0.049\n",
      "off                                                                                                                                                                -0.0130      0.039     -0.337      0.736      -0.089       0.063\n",
      "on                                                                                                                                                                 -0.0182      0.039     -0.471      0.637      -0.094       0.058\n",
      "off                                                                                                                                                                 0.0055      0.039      0.142      0.887      -0.071       0.082\n",
      "on                                                                                                                                                                 -0.0368      0.039     -0.946      0.344      -0.113       0.039\n",
      "off                                                                                                                                                                -0.0194      0.039     -0.501      0.617      -0.096       0.057\n",
      "on                                                                                                                                                                 -0.0118      0.039     -0.304      0.761      -0.088       0.064\n",
      "off                                                                                                                                                                -0.0057      0.039     -0.145      0.885      -0.082       0.071\n",
      "on                                                                                                                                                                 -0.0256      0.039     -0.655      0.513      -0.102       0.051\n",
      "off                                                                                                                                                                -0.0189      0.039     -0.485      0.628      -0.096       0.058\n",
      "on                                                                                                                                                                 -0.0123      0.039     -0.315      0.753      -0.089       0.064\n",
      "off                                                                                                                                                                -0.0139      0.039     -0.356      0.722      -0.090       0.063\n",
      "on                                                                                                                                                                 -0.0174      0.039     -0.445      0.656      -0.094       0.059\n",
      "off                                                                                                                                                                -0.0193      0.039     -0.494      0.621      -0.096       0.057\n",
      "on                                                                                                                                                                 -0.0120      0.039     -0.307      0.759      -0.088       0.065\n",
      "0.0                                                                                                                                                                -0.0074      0.421     -0.018      0.986      -0.833       0.819\n",
      "1.0                                                                                                                                                                 0.0132      0.421      0.031      0.975      -0.813       0.839\n",
      "8th grade or more                                                                                                                                                   0.0142      0.014      1.025      0.305      -0.013       0.041\n",
      "college                                                                                                                                                            -0.0163      0.016     -1.044      0.296      -0.047       0.014\n",
      "high school                                                                                                                                                         0.0201      0.013      1.501      0.133      -0.006       0.046\n",
      "less than 8th grade                                                                                                                                                 0.0090      0.016      0.578      0.563      -0.022       0.040\n",
      "technical school or some college                                                                                                                                    0.0027      0.014      0.190      0.849      -0.025       0.031\n",
      "8th grade or more                                                                                                                                                  -0.0150      0.013     -1.129      0.259      -0.041       0.011\n",
      "college                                                                                                                                                            -0.0285      0.015     -1.941      0.052      -0.057       0.000\n",
      "high school                                                                                                                                                        -0.0186      0.013     -1.447      0.148      -0.044       0.007\n",
      "less than 8th grade                                                                                                                                                -0.0041      0.015     -0.269      0.788      -0.034       0.026\n",
      "technical school or some college                                                                                                                                   -0.0080      0.014     -0.576      0.564      -0.035       0.019\n",
      "Private                                                                                                                                                             0.0116      0.034      0.341      0.733      -0.055       0.078\n",
      "Public                                                                                                                                                             -0.0103      0.031     -0.331      0.740      -0.071       0.051\n",
      "Voucher                                                                                                                                                            -0.0075      0.031     -0.244      0.807      -0.068       0.053\n",
      "A                                                                                                                                                                   0.0208      0.012      1.701      0.089      -0.003       0.045\n",
      "B                                                                                                                                                                   0.0164      0.010      1.608      0.108      -0.004       0.036\n",
      "C                                                                                                                                                                  -0.0061      0.010     -0.602      0.547      -0.026       0.014\n",
      "D                                                                                                                                                                  -0.0267      0.011     -2.404      0.016      -0.049      -0.005\n",
      "E                                                                                                                                                                  -0.0614      0.019     -3.259      0.001      -0.098      -0.024\n",
      "==============================================================================\n",
      "Omnibus:                      915.291   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3884.823\n",
      "Skew:                           0.394   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.646   Cond. No.                     1.68e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.23e-14. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# FYI\n",
    "x_OLS2 = sm.add_constant(new_x)\n",
    "results2= sm.OLS(y,x_OLS2).fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
